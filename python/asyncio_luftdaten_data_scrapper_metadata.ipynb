{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yrdqkEMTW_Ty"
   },
   "source": [
    "This scripts retrieve sensors data from the http://archive.luftdaten.info/ \n",
    "It uses as input a list of .csv sensors files url and save the resulting data as .csv\n",
    "\n",
    "**this sript does not work on windows pc because of asyncio**, in this case, you can upload this notebook on google colab.\n",
    "The asyncio library allows to run in this case 20 threads in parallel, making it much faster to scrap the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CqTE7tBDRHot"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import lxml.etree\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import re\n",
    "import io\n",
    "import sqlalchemy\n",
    "from aiohttp import ClientSession,TCPConnector\n",
    "import nest_asyncio\n",
    "import glob\n",
    "import config\n",
    "import numpy as np\n",
    "\n",
    "# asyncio and jupyter cause trouble, this is a fix :\n",
    "# https://markhneedham.com/blog/2019/05/10/jupyter-runtimeerror-this-event-loop-is-already-running/\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1\n"
     ]
    }
   ],
   "source": [
    "## beautiful asyncio needs beautiful python 3.7\n",
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "2EZiTV8Z883i",
    "outputId": "409df95a-d43b-4de5-fa76-7c6f83638201"
   },
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine(f\"sqlite:///{config.DB_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we set the date range to scrap data (luftdaten data start from 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeUUb_cy9Ph5"
   },
   "outputs": [],
   "source": [
    "def set_dt_range(start='1/1/2017'):\n",
    "    dt_range = pd.date_range(start, end=datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    dt_range = dt_range.strftime(\"%Y-%m-%d\")\n",
    "    dt_range = dt_range.tolist()\n",
    "    return dt_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(\"^.*?\\.(zip|csv)$\")\n",
    "async def fetch(dt, session):\n",
    "    url = f'http://archive.luftdaten.info/{dt}'\n",
    "   \n",
    "    files_list = []\n",
    "    try:\n",
    "        async with session.get(url) as response:\n",
    "            content = await response.text()        \n",
    "            tree = html.fromstring(content)\n",
    "            files = tree.xpath('//a/@href')\n",
    "            files_list = list(filter(regex.search, files))\n",
    "           \n",
    "            return files_list\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return files_list\n",
    "\n",
    "async def run(lista):\n",
    "   \n",
    "    tasks = []\n",
    "\n",
    "    # Fetch all responses within one Client session,\n",
    "    # keep connection alive for all requests.\n",
    "    # we set the connector to 10 because we are well educated people who play by the rules :\n",
    "    connector = TCPConnector(limit=10)\n",
    "    async with ClientSession(connector=connector) as session:\n",
    "        for dt in lista:\n",
    "            task = asyncio.ensure_future(fetch(dt, session))\n",
    "            tasks.append(task)\n",
    "\n",
    "        responses = await asyncio.gather(*tasks,return_exceptions=True )\n",
    "        # you now have all response bodies in this variable\n",
    "        return (responses)\n",
    "    \n",
    "def scrap_all_metadata(dt_lista):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = asyncio.ensure_future(run(dt_lista))\n",
    "    data = loop.run_until_complete(future)\n",
    "\n",
    "   \n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = set_dt_range(start='10/1/2015')\n",
    "\n",
    "chunks = [date_range[x:x+100] for x in range(0, len(date_range), 100)]\n",
    "\n",
    "def scrap_all_metadata():\n",
    "    for i,c in enumerate(chunks):\n",
    "        df = pd.DataFrame()\n",
    "        lista =scrap_all_metadata(c)\n",
    "        for l in lista:\n",
    "            df = pd.concat([df,pd.DataFrame(l)],axis=0)\n",
    "        df.to_csv(f'metadata_{str(i)}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in glob.glob('../data/luftdaten_metadata/*.csv', recursive=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(files[0],index_col=0)\n",
    "df.columns = ['filename']\n",
    "df['filename']= df['filename'].str.replace('.csv','').str.replace('_sensor','').str.replace('_indoor','')\n",
    "df['date']= df['filename'].str.slice(0,10)\n",
    "df['date']= pd.to_datetime(df['date'])\n",
    "df['timestamp_gmt']= df.date.astype(np.int64) / int(1e6)\n",
    "df['sensor_id']= df['filename'].str.split('_').str[-1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_metadata(file_name):\n",
    "    df = pd.read_csv(file_name,index_col=0)\n",
    "    df.columns = ['filename']\n",
    "    df['filename']= df['filename'].str.replace('.csv','').str.replace('_sensor','').str.replace('_indoor','')\n",
    "    df['date']= df['filename'].str.slice(0,10)\n",
    "    df['date']= pd.to_datetime(df['date'])\n",
    "    df['timestamp_gmt']= df.date.astype(np.int64) / int(1e6)\n",
    "    df['sensor_id']= df['filename'].str.split('_').str[-1].astype(int)\n",
    "    df['sensor_type_name']= df.filename.str.extract(r'_\\s*([^\\.]*)\\s*\\_', expand=False)\n",
    "    df[['timestamp_gmt','sensor_id','sensor_type_name']].to_sql('luftdaten_sensors_metadata', con=engine,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/luftdaten_metadata/metadata_6.csv\n",
      "../data/luftdaten_metadata/metadata_4.csv\n",
      "../data/luftdaten_metadata/metadata_3.csv\n",
      "../data/luftdaten_metadata/metadata_7.csv\n",
      "../data/luftdaten_metadata/metadata_12.csv\n",
      "../data/luftdaten_metadata/metadata_2.csv\n",
      "../data/luftdaten_metadata/metadata_0.csv\n",
      "../data/luftdaten_metadata/metadata_11.csv\n",
      "../data/luftdaten_metadata/metadata_9.csv\n",
      "../data/luftdaten_metadata/metadata_10.csv\n",
      "../data/luftdaten_metadata/metadata_8.csv\n",
      "../data/luftdaten_metadata/metadata_1.csv\n",
      "../data/luftdaten_metadata/metadata_5.csv\n",
      "../data/luftdaten_metadata/metadata_13.csv\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    print(f)\n",
    "    store_metadata(f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "asyncio_scrapper.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
